import torch
import librosa
import numpy as np
from transformers import AutoModelForCausalLM, AutoTokenizer
from tqdm import tqdm

# ğŸ“Œ è½½å…¥ GPT-2 è®­ç»ƒå¥½çš„æ¨¡å‹
MODEL_PATH = "model/taiko_model_trained_test/checkpoint-114"
model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)

# âœ… **å…³é”®ä¿®æ­£ï¼šå¢åŠ  Pad Token**
tokenizer.pad_token = tokenizer.eos_token


# **éŸ³é¢‘åˆ†æ**
def extract_bpm(audio_path):
    """ä½¿ç”¨ librosa è‡ªåŠ¨æ£€æµ‹ BPM"""
    y, sr = librosa.load(audio_path, sr=22050)
    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
    return int(tempo) if tempo else 143  # **é»˜è®¤ BPM 143**


# **æ¸…ç†ç”Ÿæˆçš„ TJA æ–‡æœ¬**
def clean_generated_text(text):
    """ç¡®ä¿ç”Ÿæˆçš„ TJA æ ¼å¼æ­£ç¡®ï¼Œç§»é™¤æ— æ•ˆå­—ç¬¦"""
    lines = text.split("\n")
    clean_lines = []
    for line in lines:
        line = line.strip()

        # ç§»é™¤ä¸ç¬¦åˆ TJA è§„èŒƒçš„æ–‡æœ¬
        if line.startswith("ç”Ÿæˆä¸€ä¸ªå¤ªé¼“è°±é¢"):
            continue  # **è·³è¿‡æ— æ•ˆçš„ GPT-2 å¤è¿°**
        if "BPMCHANGE" in line or "SCROLL" in line:
            continue  # **è·³è¿‡å¼‚å¸¸çš„æ§åˆ¶æŒ‡ä»¤**
        if len(line) < 3:
            continue  # **è¿‡æ»¤å¤ªçŸ­çš„æ— æ•ˆå†…å®¹**

        # åªä¿ç•™æœ‰æ•ˆçš„è°±é¢æ•°æ® (1~9, é€—å·)
        valid_line = ''.join(c for c in line if c in "0123456789,")
        if valid_line:
            clean_lines.append(valid_line)

    return "\n".join(clean_lines)


# **ç”Ÿæˆå®Œæ•´ TJA**
def generate_tja(audio_path, offset=0):
    """ğŸµ ç”Ÿæˆå®Œæ•´çš„ Taiko TJA è°±é¢ï¼ˆåŒ…å« 4 ä¸ªéš¾åº¦ï¼‰"""
    bpm = extract_bpm(audio_path)
    song_name = audio_path.split("/")[-1].replace(".mp3", "").replace(".wav", "")
    tja_filename = audio_path.replace(".mp3", ".tja").replace(".wav", ".tja")

    # **TJA å¤´éƒ¨ä¿¡æ¯**
    tja_content = f"""TITLE: {song_name}
BPM: {bpm}
OFFSET: {offset}
WAVE: {audio_path.split('/')[-1]}

"""

    # **ä¸åŒéš¾åº¦çš„ `TJA` ç”Ÿæˆ**
    difficulties = {
        "Easy": 3,
        "Normal": 5,
        "Hard": 7,
        "Oni": 9
    }

    for course, level in tqdm(difficulties.items(), desc="ğŸµ ç”Ÿæˆè°±é¢ä¸­..."):
        print(f"ğŸµ ç”Ÿæˆ {course} ({level}) è°±é¢ä¸­...")

        prompt = f"è¯·ç”Ÿæˆä¸€ä¸ªå¤ªé¼“è°±é¢, éš¾åº¦: {course}, BPM: {bpm}, OFFSET: {offset}, LEVEL: {level}, #START\n"

        # **GPT-2 ç”ŸæˆèŠ‚å¥æ•°æ®**
        input_data = tokenizer(
            prompt,
            return_tensors="pt",
            truncation=True,
            max_length=512,  # âœ… é™åˆ¶æœ€å¤§ Token é•¿åº¦ï¼Œé˜²æ­¢æº¢å‡º
            padding="max_length"
        )

        max_tokens = 300  # âœ… é™åˆ¶æœ€å¤§ç”Ÿæˆ Token
        with torch.no_grad():
            output = model.generate(
                input_ids=input_data["input_ids"],
                max_new_tokens=max_tokens,
                temperature=1.0,  # âœ… æ§åˆ¶éšæœºæ€§
                do_sample=True,
                top_k=50,  # âœ… é‡‡æ ·æå‡è´¨é‡
                top_p=0.95,
                pad_token_id=tokenizer.pad_token_id  # âœ… è§£å†³ IndexError
            )

        # **æ¸…ç†ç”Ÿæˆçš„è°±é¢**
        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
        generated_notes = clean_generated_text(generated_text)

        # **ç¡®ä¿è°±é¢ä¸ä¸ºç©º**
        if len(generated_notes.strip()) == 0:
            print(f"âš ï¸ ç”Ÿæˆçš„ {course} è°±é¢ä¸ºç©ºï¼Œä½¿ç”¨å ä½ç¬¦")
            generated_notes = "100000000,010000000,001000000,000100000,000010000,000001000,"

        # **åˆå¹¶ TJA å†…å®¹**
        tja_content += f"""COURSE:{course}
LEVEL:{level}
#START
{generated_notes}
#END

"""

    # **ä¿å­˜ TJA æ–‡ä»¶**
    with open(tja_filename, "w", encoding="utf-8") as f:
        f.write(tja_content)

    print(f"âœ… è°±é¢å·²ç”Ÿæˆï¼š{tja_filename}")
    return tja_filename


# **ğŸ¯ æµ‹è¯•**
if __name__ == "__main__":
    audio_file = "audio/ReadyNow.mp3"
    generate_tja(audio_file, offset=0)


