from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer
import datasets
import json

# ğŸ”¹ é€‰æ‹© GPT-2 ä½œä¸ºæ¨¡å‹
model_name = "gpt2"
tokenizer = AutoTokenizer.from_pretrained(model_name)

# ğŸ”¹ GPT-2 æ²¡æœ‰ pad_tokenï¼Œéœ€è¦æ‰‹åŠ¨è®¾ç½®
tokenizer.pad_token = tokenizer.eos_token

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(model_name)


# è¯»å– JSONL æ•°æ®å¹¶è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
def preprocess_data(file_path):
    data_list = []

    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            data = json.loads(line)

            # åªä¿ç•™æ ‡å‡†éš¾åº¦ï¼ˆå¿½ç•¥ Editï¼‰
            if data["course"].lower() == "edit":
                continue

            # æ„é€  GPT-2 é€‚åˆçš„æ–‡æœ¬æ ¼å¼
            text = (
                f"Title: {data['title']}\n"
                f"BPM: {data['bpm']}\n"
                f"Level: {data['level']}\n"
                f"Notes: {data['notes']}\n"
                f"---\n"
            )
            data_list.append({"text": text})

    return data_list


# é¢„å¤„ç†æ•°æ®
dataset = preprocess_data("data/taiko_dataset_test.jsonl")

# ä½¿ç”¨ datasets åº“åŠ è½½æ•°æ®
train_dataset = datasets.Dataset.from_dict({"text": [d["text"] for d in dataset]})


# ğŸ”¹ Tokenize æ•°æ®
def tokenize_function(examples):
    tokenized_inputs = tokenizer(
        examples["text"],
        truncation=True,
        padding="max_length",
        max_length=512
    )
    tokenized_inputs["labels"] = tokenized_inputs["input_ids"].copy()  # å…³é”®ï¼šç¡®ä¿ labels å’Œ input_ids ä¸€è‡´
    return tokenized_inputs


train_dataset = train_dataset.map(tokenize_function, batched=True)

# è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir="./model/taiko_model_trained_test",
    per_device_train_batch_size=2,
    num_train_epochs=3,
    fp16=True,
    logging_dir="./logs",
    logging_steps=10
)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    tokenizer=tokenizer
)

# è®­ç»ƒæ¨¡å‹
trainer.train()

